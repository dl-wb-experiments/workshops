{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43827516-8b8c-46ca-8ded-8a91a7bbdc78",
   "metadata": {},
   "source": [
    "## Task 1: Crop faces from the image using face detection results <a name=\"task1\"></a>\n",
    "\n",
    "We got the results of the face detector model inferece. To continue building our application, we need to use the face detection results to get the face from the full image. Let's try to do it with the first detected face."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919b0e9f-042e-410e-aa96-184efb7730cd",
   "metadata": {},
   "source": [
    "### 1. Get the first predicted face from the inferece results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ad4fd0-6cf7-4f93-9e93-87d836701a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first detected face\n",
    "detected_face_coordinates = detected_faces[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d38105-526a-4670-ac76-f6b2517276e3",
   "metadata": {},
   "source": [
    "### 2. Crop the face from the original image using slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9e1dd1-60ca-4462-adc2-a339728ea406",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin, ymin, xmax, ymax, _ = detected_face_coordinates\n",
    "\n",
    "# To get the face part of the full image, we will use slice \n",
    "face = original_image[ymin:ymax, xmin:xmax]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6d93eb-7420-4445-b654-366cc20e6db4",
   "metadata": {},
   "source": [
    "### 3. Show the face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acacdef4-8ffc-4a72-9dcb-c7abdb4b309a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show the face\n",
    "show_image(face)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0673c220-6a48-44f5-a6ba-d11cbc2ce25a",
   "metadata": {},
   "source": [
    "## Task 2: Classify the face with the mask detector <a name=\"task2\"></a>\n",
    "\n",
    "The next step is to run the mask detector inference on the face."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4a1dee-e91e-4f2f-8e9f-3a51ef82a97e",
   "metadata": {},
   "source": [
    "### 2. Read the model \n",
    "Call core.read_model to read the OpenVINO IR model. The method has two arguments:\n",
    "    \n",
    "    1. model - path to the xml model file\n",
    "    2. weights - path to the bin model file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc31e016-3d34-4a7a-a0ba-dc6ef78eee56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask_detection_model = core.read_model(mask_detection_model_xml, mask_detection_model_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242b1cad-6ec9-4c9a-97af-0a004c550101",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4. Compile the model for the device\n",
    "\n",
    "Use the instance of `Core`.\n",
    "The class `Core` has a special function called `compile_model`, which compiles a model for a device.\n",
    "This method prepares the model for inference on the device \n",
    "and returns an instance of the model prepared for an execution. \n",
    "This function has many parameters, but in this case, you need to know only two of them:\n",
    "* `model` - instance of `Model`\n",
    "* `device_name` - string, contains a device name to infer a model on CPU, GPU and other devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a963e88-5769-4efb-923f-0809310e31d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask_detector = core.compile_model(mask_detection_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f733db3-21de-4300-9618-c9b970c86070",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 6. Define the function to process the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0b27cd-23c7-4947-9a6f-999247484f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_masked(face_frame: np.ndarray) -> bool:\n",
    "    # 1. Infer the model\n",
    "    mask_detection_results = mask_detector_inference(face_frame)\n",
    "    # 2. The first value - probability of the face with a mask, the second - without a mask\n",
    "    return mask_detection_results[0] > mask_detection_results[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7157ad3b-6130-4d1e-8cf5-781cf78eeea6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task 3:  Mark people with and without a mask in the photo <a name=\"task3\"></a>\n",
    "\n",
    "In this task you need to mark people with a mask in the photo. We prepared the function to process the detected faces. You need to fill out the parts of code to cut a face from the image, put a mark on the face, and paste the processed face image to the original photo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886041eb-912a-4ba5-9c18-3b0055fd4ff9",
   "metadata": {},
   "source": [
    "### 4. Infer the model on the given image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad4788c-a257-4b41-b4d9-353b4f784d2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get shape of the original image\n",
    "original_image_height, original_image_width, _ = original_image.shape\n",
    "\n",
    "# Infer the face detector\n",
    "face_detection_inference_result = face_detector_inference(original_image)\n",
    "\n",
    "# Parse face detection inference results\n",
    "faces_coordinates = parse_face_detection_results(face_detection_inference_result, original_image_height, original_image_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e70e9c-3dda-49c8-9f83-a0943bd524f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5. Process the inference results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118f09cd-da4e-4679-8e1d-03ce7e7ad29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the resulting image\n",
    "processed_image = original_image.copy()\n",
    "\n",
    "for face_coordinates in faces_coordinates:\n",
    "    xmin, xmax, ymin, ymax, _ = face_coordinates\n",
    "    \n",
    "    # Get the face from the image\n",
    "    face = original_image[ymin:ymax, xmin:xmax]\n",
    "\n",
    "    # Run mask detector \n",
    "    is_person_masked = is_masked(face)\n",
    "    mark = green_mark if is_person_masked else red_cross\n",
    "        \n",
    "    # Replace the face with the corresponding mark\n",
    "    processed_face = put_mark_on_top_of_face(face, mark)\n",
    "    \n",
    "    processed_image[ymin:ymax, xmin:xmax] = processed_face"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbcb198-a11f-4d39-9180-a159e169cebb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task 4: Detect masks on the video <a name=\"task4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88eecfc-d267-4632-bbbe-11cca302db6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_video_stream, output_video_stream = prepare_video_streams(input_video_path, output_video_path)\n",
    "\n",
    "while input_video_stream.isOpened():\n",
    "    # 1. Read the next frame from the input video \n",
    "    return_code, original_frame = input_video_stream.read()\n",
    "    if not return_code:\n",
    "        break\n",
    "    \n",
    "    # 2. Get the frame shape\n",
    "    original_frame_height, original_frame_width,  _ = original_frame.shape\n",
    "    \n",
    "    # 3. Infer face detector\n",
    "    inference_results = face_detector_inference(original_frame)\n",
    "    \n",
    "    # 4. Parse coordinates of the detected faces\n",
    "    detected_faces = parse_face_detection_results(inference_results, original_frame_height, original_frame_width)\n",
    "    \n",
    "    for detected_face in detected_faces:\n",
    "        # 5. Get coordinates of the face\n",
    "        xmin, ymin, xmax, ymax, _ = detected_face\n",
    "        \n",
    "        # 6. Crop the face from the frame\n",
    "        face = original_frame[ymin:ymax, xmin:xmax]\n",
    "        \n",
    "        # 7. Run inference of the mask detector\n",
    "        is_person_masked = is_masked(face)\n",
    "        mark = green_mark if is_person_masked else red_cross\n",
    "        \n",
    "        # 8. Replace the face with the corresponding mark\n",
    "        processed_face = put_mark_on_top_of_face(face, mark)\n",
    "    \n",
    "        # 9. Past processed face to the frame\n",
    "        original_frame[ymin:ymax, xmin:xmax] = processed_face\n",
    "    \n",
    "    \n",
    "    # 10. Write the resulting frame to the output stream\n",
    "    output_video_stream.write(original_frame)\n",
    "    \n",
    "\n",
    "input_video_stream.release()\n",
    "# Save the resulting video\n",
    "output_video_stream.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
