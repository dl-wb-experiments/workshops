{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43827516-8b8c-46ca-8ded-8a91a7bbdc78",
   "metadata": {},
   "source": [
    "## Task 1: Crop faces from the image using face detection results <a name=\"task1\"></a>\n",
    "\n",
    "We got the results of the face detector model inferece. To continue building our application, we need to use the face detection results to get the face from the full image. Let's try to do it with the first detected face."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265fb202-0bcf-4bad-8846-ec6fc5fb1ace",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. Get the first predicted face from the inferece results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5bd71925-9823-44a5-ad21-5a9ff3d017b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_face = detected_faces[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fe8c4b-c216-48d6-831f-7577e9f83435",
   "metadata": {},
   "source": [
    "### 2. Crop the face from the original image using slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "69da93a2-6f1d-4f40-9a05-e61e4f2ebcc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Unpack the coordinates from detected_face\n",
    "xmin = detected_face[0]\n",
    "ymin = detected_face[1]\n",
    "xmax = detected_face[2]\n",
    "ymax = detected_face[3]\n",
    "\n",
    "# To get the face part of the full image, we will use slice \n",
    "# Example, if a face has the coordinates (100,200) (300,400), write: original_image[100:300, 200:400]\n",
    "face = original_image[ymin:ymax, xmin:xmax]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0673c220-6a48-44f5-a6ba-d11cbc2ce25a",
   "metadata": {},
   "source": [
    "## Task 2: Classify the face with the mask detector <a name=\"task2\"></a>\n",
    "\n",
    "The next step is to run the mask detector inference on the face."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4a1dee-e91e-4f2f-8e9f-3a51ef82a97e",
   "metadata": {},
   "source": [
    "### 2. Read the model \n",
    "Call core.read_model to read the OpenVINO IR model. The method has two arguments:\n",
    "    \n",
    "    1. model - path to the xml model file\n",
    "    2. weights - path to the bin model file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc31e016-3d34-4a7a-a0ba-dc6ef78eee56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask_detection_model = core.read_model(mask_detection_model_xml, mask_detection_model_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242b1cad-6ec9-4c9a-97af-0a004c550101",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4. Compile the model for the device\n",
    "\n",
    "Use the instance of `Core`.\n",
    "The class `Core` has a special function called `compile_model`, which compiles a model for a device.\n",
    "This method prepares the model for inference on the device \n",
    "and returns an instance of the model prepared for an execution. \n",
    "This function has many parameters, but in this case, you need to know only two of them:\n",
    "* `model` - instance of `Model`\n",
    "* `device_name` - string, contains a device name to infer a model on CPU, GPU and other devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a963e88-5769-4efb-923f-0809310e31d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask_detector = core.compile_model(mask_detection_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f733db3-21de-4300-9618-c9b970c86070",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 6. Define the function to process the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0b27cd-23c7-4947-9a6f-999247484f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_masked(face: np.ndarray) -> bool:\n",
    "    # 1. Infer the model, get predicted probabilities\n",
    "    mask_detection_results = mask_detector_inference(face)\n",
    "    \n",
    "    # 2. The first value - probability of the face with a mask, the second - without a mask\n",
    "    with_mask_probability = mask_detection_results[0]\n",
    "    without_mask_probability = mask_detection_results[1]\n",
    "    \n",
    "    # 3. compare probs\n",
    "    has_mask = with_mask_probability > without_mask_probability\n",
    "    \n",
    "    return has_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7157ad3b-6130-4d1e-8cf5-781cf78eeea6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task 3:  Mark people with and without a mask in the photo <a name=\"task3\"></a>\n",
    "\n",
    "In this task you need to mark people with a mask in the photo. We prepared the function to process the detected faces. You need to fill out the parts of code to cut a face from the image, put a mark on the face, and paste the processed face image to the original photo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886041eb-912a-4ba5-9c18-3b0055fd4ff9",
   "metadata": {},
   "source": [
    "### 4. Infer the model on the given image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad4788c-a257-4b41-b4d9-353b4f784d2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get shape of the original image\n",
    "original_image_height, original_image_width, _ = original_image.shape\n",
    "\n",
    "# Infer the face detector\n",
    "face_detection_inference_result = face_detector_inference(original_image)\n",
    "\n",
    "# Parse face detection inference results\n",
    "faces_coordinates = parse_face_detection_results(face_detection_inference_result, original_image_height, original_image_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e70e9c-3dda-49c8-9f83-a0943bd524f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5. Process the inference results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118f09cd-da4e-4679-8e1d-03ce7e7ad29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the resulting image\n",
    "processed_image = original_image.copy()\n",
    "\n",
    "for face_coordinates in faces_coordinates:\n",
    "    xmin, xmax, ymin, ymax, _ = face_coordinates\n",
    "    \n",
    "    # Get the face from the image\n",
    "    face = original_image[ymin:ymax, xmin:xmax]\n",
    "\n",
    "    # Run mask detector \n",
    "    is_person_masked = is_masked(face)\n",
    "    mark = green_mark if is_person_masked else red_cross\n",
    "        \n",
    "    # Replace the face with the corresponding mark\n",
    "    processed_face = put_mark_on_top_of_face(face, mark)\n",
    "    \n",
    "    processed_image[ymin:ymax, xmin:xmax] = processed_face"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbcb198-a11f-4d39-9180-a159e169cebb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task 4: Detect masks on the video <a name=\"task4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88eecfc-d267-4632-bbbe-11cca302db6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the resulting image\n",
    "processed_image = original_image.copy()\n",
    "\n",
    "for face_coordinates in faces_coordinates:\n",
    "    xmin = face_coordinates[0]\n",
    "    ymin = face_coordinates[1]\n",
    "    xmax = face_coordinates[2]\n",
    "    ymax = face_coordinates[3]\n",
    "    \n",
    "    # To get the face part of the full image, we will use slice \n",
    "    # Example, if a face has the coordinates (100,200) (300,400), write: original_image[100:300, 200:400]\n",
    "    face = original_image[ymin:ymax, xmin:xmax]\n",
    "\n",
    "    # Run mask detector \n",
    "    is_person_masked = is_masked(face)\n",
    "    mark = green_mark if is_person_masked else red_cross\n",
    "        \n",
    "    # Replace the face with the corresponding mark\n",
    "    processed_face = put_mark_on_top_of_face(face, mark)\n",
    "    \n",
    "    # Use the same mechanism as to get the face\n",
    "    processed_image[ymin:ymax, xmin:xmax] = processed_face"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
